{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# G12 | DMYTRO VERNYUK Y MIKHAIL RONCHYK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practica 2 - Parte 1: Análisis de sentimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = 911 # Numero para los parametros aleatorios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Data  Target\n",
       "0                           Wow... Loved this place.       1\n",
       "1                                 Crust is not good.       0\n",
       "2          Not tasty and the texture was just nasty.       0\n",
       "3  Stopped by during the late May bank holiday of...       1\n",
       "4  The selection on the menu was great and so wer...       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('yelp_labelled.txt', sep='\\t', header=None)\n",
    "df.columns = [\"Data\", \"Target\"]\n",
    "target_names = ['negative opinion', 'positive opinion']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(df['Data'])\n",
    "target = np.array(df['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_terms (feature_names, data, vector_data, index):\n",
    "    '''\n",
    "    Escribe los términos presentes en un mensaje representado como bolsa de palabras.\n",
    "    \n",
    "    - feature_names: terminos usados para vectorizar\n",
    "    - data: lista de mensajes original (si data==None no se muestra el mensaje original)\n",
    "    - vector_data: matriz (dispersa) de mensaje vectorizados\n",
    "    - index: posición del mensaje a mostrar\n",
    "    '''\n",
    "    # máscara para seleccionar sólo el mensaje en posición index\n",
    "    mask=vector_data[index,:]>0\n",
    "    \n",
    "    # términos que aparecen en ese mensaje vectorizado\n",
    "    terminos = ma.array(feature_names, mask = ~(mask[0].toarray()))\n",
    "    \n",
    "    # mostrar mensaje original\n",
    "    if data:\n",
    "        print('Mensaje', index, ':', data[index])\n",
    "    \n",
    "    # mostrar términos que aparecen en el mensaje vectorizado\n",
    "    print('Mensaje', index, 'vectorizado:', terminos.compressed(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.25, random_state=rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- # binary = True && ngram_range = (1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bolsa de palabras\n",
    "vectorizer = CountVectorizer(stop_words='english', binary=True, ngram_range=(1,1))\n",
    "\n",
    "train_vector_data = vectorizer.fit_transform(X_train)\n",
    "test_vector_data=vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1547\n",
      "Mensaje 10 vectorizado: ['beef' 'good' 'really' 'roast' 'sandwich' 'tasted'] \n",
      "\n",
      "Mensaje 100 vectorizado: ['special'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extra\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "print(len(feature_names))\n",
    "\n",
    "write_terms(feature_names, None, train_vector_data, 10)\n",
    "write_terms(feature_names, None, train_vector_data, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes, porcentaje de aciertos en entrenamiento: 0.9506666666666667\n",
      "Multinomial Naive Bayes, porcentaje de aciertos en test: 0.808\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Multinomial\n",
    "mnb_classifier = MultinomialNB()\n",
    "\n",
    "mnb_classifier.fit(train_vector_data, y_train)\n",
    "\n",
    "mnb_train_predictions = mnb_classifier.predict(train_vector_data)\n",
    "mnb_test_predictions = mnb_classifier.predict(test_vector_data)\n",
    "\n",
    "print(\"Multinomial Naive Bayes, porcentaje de aciertos en entrenamiento:\", np.mean(mnb_train_predictions == y_train))\n",
    "print(\"Multinomial Naive Bayes, porcentaje de aciertos en test:\", np.mean(mnb_test_predictions == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "negative opinion       0.81      0.79      0.80       120\n",
      "positive opinion       0.81      0.82      0.82       130\n",
      "\n",
      "        accuracy                           0.81       250\n",
      "       macro avg       0.81      0.81      0.81       250\n",
      "    weighted avg       0.81      0.81      0.81       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extra\n",
    "classifier=mnb_classifier\n",
    "predictions = mnb_test_predictions\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.5, 1.5]), <a list of 2 Text xticklabel objects>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extra\n",
    "%matplotlib inline\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=target_names, columns=target_names)\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "sn.heatmap(conf_matrix_df, annot=True, vmin=0, vmax=conf_matrix.max(), fmt='d', cmap=\"YlGnBu\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.xticks(rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top20_features_per_class_in_NB(vectorizer, clf, class_labels):\n",
    "    \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    print(\"Top 20 features per class\\n\")\n",
    "    for i, class_label in enumerate(class_labels):\n",
    "        top20 = np.argsort(clf.feature_log_prob_[i])[-20:]\n",
    "        reversed_top = top20[::-1]\n",
    "        \n",
    "        print(\"%s: %s\" % (class_label,\n",
    "              \" / \".join(feature_names[j] for j in reversed_top)),'\\n')\n",
    "        \n",
    "        #Descomentar para ver el índice de los términos en el diccionario\n",
    "        #print(\"%s \" % (\" / \".join(str(j) for j in reversed_top)),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 features per class\n",
      "\n",
      "negative opinion: food / place / service / like / good / time / don / just / ve / minutes / won / think / got / bad / worst / wasn / going / disappointed / really / better \n",
      "\n",
      "positive opinion: good / great / food / place / service / nice / friendly / time / delicious / really / just / best / amazing / vegas / restaurant / fantastic / fresh / staff / like / pretty \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extra\n",
    "print_top20_features_per_class_in_NB(vectorizer,mnb_classifier,target_names)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes, porcentaje de aciertos en entrenamiento: 0.9293333333333333\n",
      "Gaussian Naive Bayes, porcentaje de aciertos en test: 0.636\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Gaussiano\n",
    "gnb_classifier = GaussianNB()\n",
    "\n",
    "chunk_size=100\n",
    "num_rows=len(y_train)\n",
    "\n",
    "for i in range(0, (num_rows//chunk_size)):\n",
    "    train_chunk = train_vector_data[i*chunk_size : (i+1)*chunk_size,:].toarray()\n",
    "    target_chunk = y_train[i*chunk_size : (i+1)*chunk_size]\n",
    "    gnb_classifier.partial_fit(train_chunk, target_chunk, classes=np.unique(y_train))\n",
    "\n",
    "\n",
    "gnb_train_predictions=np.zeros_like(y_train)\n",
    "gnb_test_predictions=np.zeros_like(y_test)\n",
    "\n",
    "for i in range(0, (num_rows//chunk_size)):\n",
    "    train_chunk = train_vector_data[i*chunk_size : (i+1)*chunk_size,:].toarray()\n",
    "    gnb_train_predictions[i*chunk_size : (i+1)*chunk_size] = gnb_classifier.predict(train_chunk)\n",
    "    \n",
    "num_rows=len(y_test)\n",
    "for i in range(0, (num_rows//chunk_size)):\n",
    "    test_chunk = test_vector_data[i*chunk_size : (i+1)*chunk_size,:].toarray()\n",
    "    gnb_test_predictions[i*chunk_size : (i+1)*chunk_size] = gnb_classifier.predict(test_chunk)\n",
    "\n",
    "print(\"Gaussian Naive Bayes, porcentaje de aciertos en entrenamiento:\", np.mean(gnb_train_predictions == y_train))\n",
    "print(\"Gaussian Naive Bayes, porcentaje de aciertos en test:\", np.mean(gnb_test_predictions == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># Árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árbol, porcentaje de aciertos en entrenamiento: 0.9986666666666667\n",
      "Árbol, porcentaje de aciertos en test: 0.756\n"
     ]
    }
   ],
   "source": [
    "tree_classifier = tree.DecisionTreeClassifier(criterion=\"entropy\",random_state=rand, max_depth = 140, min_samples_leaf =1)\n",
    "                                            # max_depth | min_samples_leaf | max_leaf_nodes\n",
    "                                            # encontrar el mejor arbol con uno de los parametros\n",
    "                                            #if you specify max_leaf_nodes, max_depth is ignored\n",
    "tree_classifier.fit(train_vector_data, y_train)\n",
    "\n",
    "tree_train_predictions = tree_classifier.predict(train_vector_data)\n",
    "tree_test_predictions = tree_classifier.predict(test_vector_data)\n",
    "\n",
    "print(\"Árbol, porcentaje de aciertos en entrenamiento:\", np.mean(tree_train_predictions == y_train))\n",
    "print(\"Árbol, porcentaje de aciertos en test:\", np.mean(tree_test_predictions == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top20_features_in_trees(vectorizer, clf):\n",
    "    \"\"\"Prints features with the highest coefficient values\"\"\"\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    \n",
    "    top20 = np.argsort(clf.feature_importances_)[-20:]\n",
    "    reversed_top = top20[::-1]\n",
    "    print(\"Top 20 features in the tree\\n\")\n",
    "    print(\"%s\" % ( \" / \".join(feature_names[j] for j in reversed_top)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 features in the tree\n",
      "\n",
      "great / delicious / good / fantastic / nice / amazing / happy / loved / excellent / awesome / perfect / friendly / food / love / minutes / disappointed / service / best / bread / spot\n"
     ]
    }
   ],
   "source": [
    "# Extra\n",
    "print_top20_features_in_trees(vectorizer,tree_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- # binary = False && ngram_range = (1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bolsa de palabras\n",
    "vectorizer = CountVectorizer(stop_words='english', binary=False, ngram_range=(1,1))\n",
    "\n",
    "train_vector_data = vectorizer.fit_transform(X_train)\n",
    "test_vector_data=vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF \n",
    "tfidfer = TfidfTransformer()\n",
    "\n",
    "train_preprocessed = tfidfer.fit_transform(train_vector_data)\n",
    "test_preprocessed=tfidfer.transform(test_vector_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes, porcentaje de aciertos en entrenamiento: 0.9653333333333334\n",
      "Multinomial Naive Bayes, porcentaje de aciertos en test: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Multinomial\n",
    "mnb_classifier = MultinomialNB()\n",
    "\n",
    "mnb_classifier.fit(train_preprocessed, y_train)\n",
    "\n",
    "mnb_train_predictions = mnb_classifier.predict(train_preprocessed)\n",
    "mnb_test_predictions = mnb_classifier.predict(test_preprocessed)\n",
    "\n",
    "print(\"Multinomial Naive Bayes, porcentaje de aciertos en entrenamiento:\", np.mean(mnb_train_predictions == y_train))\n",
    "print(\"Multinomial Naive Bayes, porcentaje de aciertos en test:\", np.mean(mnb_test_predictions == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes, porcentaje de aciertos en entrenamiento: 0.9306666666666666\n",
      "Gaussian Naive Bayes, porcentaje de aciertos en test: 0.636\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Gaussiano\n",
    "gnb_classifier = GaussianNB()\n",
    "\n",
    "chunk_size=100\n",
    "num_rows=len(y_train)\n",
    "\n",
    "for i in range(0, (num_rows//chunk_size)):\n",
    "    train_chunk = train_preprocessed[i*chunk_size : (i+1)*chunk_size,:].toarray()\n",
    "    target_chunk = y_train[i*chunk_size : (i+1)*chunk_size]\n",
    "    gnb_classifier.partial_fit(train_chunk, target_chunk, classes=np.unique(y_train))\n",
    "\n",
    "\n",
    "gnb_train_predictions=np.zeros_like(y_train)\n",
    "gnb_test_predictions=np.zeros_like(y_test)\n",
    "\n",
    "for i in range(0, (num_rows//chunk_size)):\n",
    "    train_chunk = train_preprocessed[i*chunk_size : (i+1)*chunk_size,:].toarray()\n",
    "    gnb_train_predictions[i*chunk_size : (i+1)*chunk_size] = gnb_classifier.predict(train_chunk)\n",
    "    \n",
    "num_rows=len(y_test)\n",
    "for i in range(0, (num_rows//chunk_size)):\n",
    "    test_chunk = test_preprocessed[i*chunk_size : (i+1)*chunk_size,:].toarray()\n",
    "    gnb_test_predictions[i*chunk_size : (i+1)*chunk_size] = gnb_classifier.predict(test_chunk)\n",
    "\n",
    "print(\"Gaussian Naive Bayes, porcentaje de aciertos en entrenamiento:\", np.mean(gnb_train_predictions == y_train))\n",
    "print(\"Gaussian Naive Bayes, porcentaje de aciertos en test:\", np.mean(gnb_test_predictions == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># Árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árbol, porcentaje de aciertos en entrenamiento: 0.9986666666666667\n",
      "Árbol, porcentaje de aciertos en test: 0.752\n"
     ]
    }
   ],
   "source": [
    "tree_classifier = tree.DecisionTreeClassifier(criterion=\"entropy\",random_state=rand,  max_depth = 203, min_samples_leaf =1)\n",
    "                                            # max_depth | min_samples_leaf | max_leaf_nodes\n",
    "tree_classifier.fit(train_preprocessed, y_train)\n",
    "\n",
    "tree_train_predictions = tree_classifier.predict(train_preprocessed)\n",
    "tree_test_predictions = tree_classifier.predict(test_preprocessed)\n",
    "\n",
    "print(\"Árbol, porcentaje de aciertos en entrenamiento:\", np.mean(tree_train_predictions == y_train))\n",
    "print(\"Árbol, porcentaje de aciertos en test:\", np.mean(tree_test_predictions == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- # binary = True && ngram_range = (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bolsa de palabras\n",
    "vectorizer = CountVectorizer(stop_words='english', binary=True, ngram_range=(1,2))\n",
    "\n",
    "train_vector_data = vectorizer.fit_transform(X_train)\n",
    "test_vector_data=vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes, porcentaje de aciertos en entrenamiento: 0.984\n",
      "Multinomial Naive Bayes, porcentaje de aciertos en test: 0.812\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Multinomial\n",
    "mnb_classifier = MultinomialNB()\n",
    "\n",
    "mnb_classifier.fit(train_vector_data, y_train)\n",
    "\n",
    "mnb_train_predictions = mnb_classifier.predict(train_vector_data)\n",
    "mnb_test_predictions = mnb_classifier.predict(test_vector_data)\n",
    "\n",
    "print(\"Multinomial Naive Bayes, porcentaje de aciertos en entrenamiento:\", np.mean(mnb_train_predictions == y_train))\n",
    "print(\"Multinomial Naive Bayes, porcentaje de aciertos en test:\", np.mean(mnb_test_predictions == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes, porcentaje de aciertos en entrenamiento: 0.956\n",
      "Gaussian Naive Bayes, porcentaje de aciertos en test: 0.648\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Gaussiano\n",
    "gnb_classifier = GaussianNB()\n",
    "\n",
    "chunk_size=100\n",
    "num_rows=len(y_train)\n",
    "\n",
    "for i in range(0, (num_rows//chunk_size)):\n",
    "    train_chunk = train_vector_data[i*chunk_size : (i+1)*chunk_size,:].toarray()\n",
    "    target_chunk = y_train[i*chunk_size : (i+1)*chunk_size]\n",
    "    gnb_classifier.partial_fit(train_chunk, target_chunk, classes=np.unique(y_train))\n",
    "\n",
    "\n",
    "gnb_train_predictions=np.zeros_like(y_train)\n",
    "gnb_test_predictions=np.zeros_like(y_test)\n",
    "\n",
    "for i in range(0, (num_rows//chunk_size)):\n",
    "    train_chunk = train_vector_data[i*chunk_size : (i+1)*chunk_size,:].toarray()\n",
    "    gnb_train_predictions[i*chunk_size : (i+1)*chunk_size] = gnb_classifier.predict(train_chunk)\n",
    "    \n",
    "num_rows=len(y_test)\n",
    "for i in range(0, (num_rows//chunk_size)):\n",
    "    test_chunk = test_vector_data[i*chunk_size : (i+1)*chunk_size,:].toarray()\n",
    "    gnb_test_predictions[i*chunk_size : (i+1)*chunk_size] = gnb_classifier.predict(test_chunk)\n",
    "\n",
    "print(\"Gaussian Naive Bayes, porcentaje de aciertos en entrenamiento:\", np.mean(gnb_train_predictions == y_train))\n",
    "print(\"Gaussian Naive Bayes, porcentaje de aciertos en test:\", np.mean(gnb_test_predictions == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># Árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árbol, porcentaje de aciertos en entrenamiento: 0.9973333333333333\n",
      "Árbol, porcentaje de aciertos en test: 0.744\n"
     ]
    }
   ],
   "source": [
    "tree_classifier = tree.DecisionTreeClassifier(criterion=\"entropy\",random_state=rand, max_depth = 145, min_samples_leaf = 1)\n",
    "                                            # max_depth | min_samples_leaf | max_leaf_nodes\n",
    "tree_classifier.fit(train_vector_data, y_train)\n",
    "\n",
    "tree_train_predictions = tree_classifier.predict(train_vector_data)\n",
    "tree_test_predictions = tree_classifier.predict(test_vector_data)\n",
    "\n",
    "print(\"Árbol, porcentaje de aciertos en entrenamiento:\", np.mean(tree_train_predictions == y_train))\n",
    "print(\"Árbol, porcentaje de aciertos en test:\", np.mean(tree_test_predictions == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- # binary = False && ngram_range = (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bolsa de palabras\n",
    "vectorizer = CountVectorizer(stop_words='english', binary=False, ngram_range=(1,2))\n",
    "\n",
    "train_vector_data = vectorizer.fit_transform(X_train)\n",
    "test_vector_data=vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF \n",
    "tfidfer = TfidfTransformer()\n",
    "\n",
    "train_preprocessed = tfidfer.fit_transform(train_vector_data)\n",
    "test_preprocessed=tfidfer.transform(test_vector_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes, porcentaje de aciertos en entrenamiento: 0.9933333333333333\n",
      "Multinomial Naive Bayes, porcentaje de aciertos en test: 0.828\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Multinomial\n",
    "mnb_classifier = MultinomialNB()\n",
    "\n",
    "mnb_classifier.fit(train_preprocessed, y_train)\n",
    "\n",
    "mnb_train_predictions = mnb_classifier.predict(train_preprocessed)\n",
    "mnb_test_predictions = mnb_classifier.predict(test_preprocessed)\n",
    "\n",
    "print(\"Multinomial Naive Bayes, porcentaje de aciertos en entrenamiento:\", np.mean(mnb_train_predictions == y_train))\n",
    "print(\"Multinomial Naive Bayes, porcentaje de aciertos en test:\", np.mean(mnb_test_predictions == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes, porcentaje de aciertos en entrenamiento: 0.9586666666666667\n",
      "Gaussian Naive Bayes, porcentaje de aciertos en test: 0.644\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Gaussiano\n",
    "gnb_classifier = GaussianNB()\n",
    "\n",
    "chunk_size=100\n",
    "num_rows=len(y_train)\n",
    "\n",
    "for i in range(0, (num_rows//chunk_size)):\n",
    "    train_chunk = train_preprocessed[i*chunk_size : (i+1)*chunk_size,:].toarray()\n",
    "    target_chunk = y_train[i*chunk_size : (i+1)*chunk_size]\n",
    "    gnb_classifier.partial_fit(train_chunk, target_chunk, classes=np.unique(y_train))\n",
    "\n",
    "\n",
    "gnb_train_predictions=np.zeros_like(y_train)\n",
    "gnb_test_predictions=np.zeros_like(y_test)\n",
    "\n",
    "for i in range(0, (num_rows//chunk_size)):\n",
    "    train_chunk = train_preprocessed[i*chunk_size : (i+1)*chunk_size,:].toarray()\n",
    "    gnb_train_predictions[i*chunk_size : (i+1)*chunk_size] = gnb_classifier.predict(train_chunk)\n",
    "    \n",
    "num_rows=len(y_test)\n",
    "for i in range(0, (num_rows//chunk_size)):\n",
    "    test_chunk = test_preprocessed[i*chunk_size : (i+1)*chunk_size,:].toarray()\n",
    "    gnb_test_predictions[i*chunk_size : (i+1)*chunk_size] = gnb_classifier.predict(test_chunk)\n",
    "\n",
    "print(\"Gaussian Naive Bayes, porcentaje de aciertos en entrenamiento:\", np.mean(gnb_train_predictions == y_train))\n",
    "print(\"Gaussian Naive Bayes, porcentaje de aciertos en test:\", np.mean(gnb_test_predictions == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># Árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árbol, porcentaje de aciertos en entrenamiento: 0.9986666666666667\n",
      "Árbol, porcentaje de aciertos en test: 0.74\n"
     ]
    }
   ],
   "source": [
    "tree_classifier = tree.DecisionTreeClassifier(criterion=\"entropy\",random_state=rand, max_depth = 136,  min_samples_leaf = 1)\n",
    "                                            # max_depth | min_samples_leaf | max_leaf_nodes\n",
    "tree_classifier.fit(train_preprocessed, y_train)\n",
    "\n",
    "tree_train_predictions = tree_classifier.predict(train_preprocessed)\n",
    "tree_test_predictions = tree_classifier.predict(test_preprocessed)\n",
    "\n",
    "print(\"Árbol, porcentaje de aciertos en entrenamiento:\", np.mean(tree_train_predictions == y_train))\n",
    "print(\"Árbol, porcentaje de aciertos en test:\", np.mean(tree_test_predictions == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- # Preguntas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "?????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartado b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
